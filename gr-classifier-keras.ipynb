{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import model_selection\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  text type labels  \\\n",
      "0    The first option that Derek could choose is to...  opt      0   \n",
      "1                                      give his kidney  act      1   \n",
      "2                                        let george go  act      1   \n",
      "3                           give the enemy information  act      1   \n",
      "4                                                 kill  act      0   \n",
      "5                                       refuse to kill  act      1   \n",
      "6                     She can return the ring to Jesse  opt      1   \n",
      "7                                        keep the ring  act      0   \n",
      "8                        Hauke can give back the ring.  opt      1   \n",
      "9                                      return the ring  act      1   \n",
      "10                        Julio was asked to kill Maxi  opt      0   \n",
      "11                                refuse to kill quinn  act      1   \n",
      "12                            refuse to accept the job  act      1   \n",
      "13   Peter wants to do a plagiarism check of his st...  opt      1   \n",
      "14          He can correct homework by hand, as before  opt      1   \n",
      "15                           Andrea can punish the cat  opt      0   \n",
      "16                               I can ignore the loss  opt      0   \n",
      "17                                      keep the purse  act      0   \n",
      "18                                    return the purse  act      1   \n",
      "19                                                kill  act      0   \n",
      "20                                       keep the ring  act      0   \n",
      "21                                     return the ring  act      1   \n",
      "22                                       keep the ring  act      0   \n",
      "23                                     return the ring  act      1   \n",
      "24                              refuse to kill the cat  act      1   \n",
      "25                               Thomas will kill Maxi  opt      0   \n",
      "26                                 refuse to kill maxi  act      1   \n",
      "27                                             killing  act      0   \n",
      "28                              refuse to kill the dog  act      1   \n",
      "29                                    I keep the money  act      0   \n",
      "..                                                 ...  ...    ...   \n",
      "147               Peter can correct homework as before  opt      1   \n",
      "148  I have hear that my colleague is giving inform...  opt      0   \n",
      "149                                  keep my knowledge  act      0   \n",
      "150                       Dominique can talk to Sascha  opt      0   \n",
      "151                                        tell george  act      0   \n",
      "152                                    give his kidney  act      0   \n",
      "153                                    give his kidney  act      1   \n",
      "154  Derek could also just treat GeorgeÂ´s minor inj...  opt      1   \n",
      "155           Tell the police what he knows about Paul  opt      0   \n",
      "156                           He can lie to his mother  opt      0   \n",
      "157                  Quinn can save Nele from drowning  opt      0   \n",
      "158                Robi can save \"Maria\" from drowning  opt      0   \n",
      "159                                         save paula  act      1   \n",
      "160           Ben could save Robi from a burning house  opt      1   \n",
      "161                                           rescuing  act      1   \n",
      "162                                           rescuing  act      1   \n",
      "163                                   Take Luis's Side  opt      1   \n",
      "164            Go to bed early but miss out on the fun  opt      1   \n",
      "165                                           Run away  opt      0   \n",
      "166                                    save the people  act      1   \n",
      "167                    refrain from shooting the plane  act      0   \n",
      "168                                    shoot the plane  act      0   \n",
      "169                                not shoot the plane  act      1   \n",
      "170                                                lie  act      0   \n",
      "171                                     tell the truth  act      1   \n",
      "172                                                lie  act      0   \n",
      "173                                     tell the truth  act      1   \n",
      "174            Georgina can save Charlie or save Chris  opt      1   \n",
      "175                    She could surrender to an enemy  opt      1   \n",
      "176                        Georgina could save neither  opt      0   \n",
      "\n",
      "    deontic_modality  \n",
      "0                  0  \n",
      "1                  0  \n",
      "2                  0  \n",
      "3                  0  \n",
      "4                  0  \n",
      "5                  0  \n",
      "6                  0  \n",
      "7                  0  \n",
      "8                  0  \n",
      "9                  0  \n",
      "10                 0  \n",
      "11                 0  \n",
      "12                 0  \n",
      "13                 0  \n",
      "14                 0  \n",
      "15                 0  \n",
      "16                 0  \n",
      "17                 0  \n",
      "18                 0  \n",
      "19                 0  \n",
      "20                 0  \n",
      "21                 0  \n",
      "22                 0  \n",
      "23                 0  \n",
      "24                 0  \n",
      "25                 0  \n",
      "26                 0  \n",
      "27                 0  \n",
      "28                 0  \n",
      "29                 0  \n",
      "..               ...  \n",
      "147                0  \n",
      "148                1  \n",
      "149                2  \n",
      "150                3  \n",
      "151                2  \n",
      "152                0  \n",
      "153                1  \n",
      "154                3  \n",
      "155                2  \n",
      "156                2  \n",
      "157                3  \n",
      "158                1  \n",
      "159                3  \n",
      "160                3  \n",
      "161                3  \n",
      "162                3  \n",
      "163                1  \n",
      "164                1  \n",
      "165                1  \n",
      "166                3  \n",
      "167                1  \n",
      "168                3  \n",
      "169                1  \n",
      "170                2  \n",
      "171                3  \n",
      "172                2  \n",
      "173                3  \n",
      "174                1  \n",
      "175                1  \n",
      "176                0  \n",
      "\n",
      "[177 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(500)\n",
    "\n",
    "df = pd.read_csv('model/moral-data.csv', sep=';')\n",
    "df.drop(['deontic_modality', 'type'], axis=1)\n",
    "df.rename(columns={'general_rule': 'labels'}, inplace=True)\n",
    "print(df)\n",
    "\n",
    "# Step 1: Remove blank rows if any.\n",
    "df['text'].dropna(inplace=True)\n",
    "\n",
    "# Step 2: Change all the text to lower case\n",
    "df['text'] = [entry.lower() for entry in df['text']]\n",
    "\n",
    "# Step 3: Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "for index, entry in enumerate(df['text']):\n",
    "    final_words = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for word, tag in pos_tag(entry):\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            final_word = lemmatizer.lemmatize(word, tag_map[tag[0]])\n",
    "            final_words.append(final_word)\n",
    "    df.loc[index,'text'] = str(final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5abd7da3292c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtest_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mtrain_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtest_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_Y, test_Y = model_selection.train_test_split(df['text'],df['labels'],test_size=0.2)\n",
    "\n",
    "max_words = 1000\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
    "tokenize.fit_on_texts(train_X) # only fit on train\n",
    "\n",
    "train_X = tokenize.texts_to_matrix(train_X)\n",
    "test_X = tokenize.texts_to_matrix(test_X)\n",
    "\n",
    "num_classes = np.max(train_Y) + 1\n",
    "train_Y = utils.to_categorical(train_Y, num_classes)\n",
    "test_Y = utils.to_categorical(test_Y, num_classes)\n",
    "\n",
    "batch_size = 2\n",
    "epochs = 80\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "              \n",
    "history = model.fit(train_X, train_Y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_X, test_Y, batch_size=batch_size, verbose=1)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f3dcd5937e01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'return the ring'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(tokenize.texts_to_matrix('return the ring'))\n",
    "predicted_label = np.argmax(prediction[0])\n",
    "print(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimieren: https://realpython.com/python-keras-text-classification/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
