{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "np.random.seed(500)\n",
    "\n",
    "df_corpus = pd.read_csv('model/moral-data.csv', sep=';')\n",
    "df_corpus.drop(['deontic_modality', 'type'], axis=1)\n",
    "df_corpus.rename(columns={'general_rule': 'labels'}, inplace=True)\n",
    "\n",
    "# Step - a : Remove blank rows if any.\n",
    "df_corpus['text'].dropna(inplace=True)\n",
    "\n",
    "# Step - b : Change all the text to lower case\n",
    "df_corpus['text'] = [entry.lower() for entry in df_corpus['text']]\n",
    "\n",
    "# Step - c : Tokenization\n",
    "df_corpus['text'] = [word_tokenize(entry) for entry in df_corpus['text']]\n",
    "\n",
    "# Step - d : Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "for index, entry in enumerate(df_corpus['text']):\n",
    "    final_words = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for word, tag in pos_tag(entry):\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            final_word = lemmatizer.lemmatize(word, tag_map[tag[0]])\n",
    "            final_words.append(final_word)\n",
    "    df_corpus.loc[index,'text_processed'] = str(final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = model_selection.train_test_split(df_corpus['text_processed'],df_corpus['labels'],test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  77.77777777777779\n"
     ]
    }
   ],
   "source": [
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(train_X, train_Y)\n",
    "predictions_nb = nb.predict(test_X)\n",
    "\n",
    "print(\"Naive Bayes Accuracy Score -> \", accuracy_score(predictions_nb, test_Y)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  83.33333333333334\n"
     ]
    }
   ],
   "source": [
    "svm = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SVC(C=1.0, kernel='linear', degree=3, gamma='auto', probability=True)),\n",
    "               ])\n",
    "svm.fit(train_X, train_Y)\n",
    "predictions_svm = svm.predict(test_X)\n",
    "\n",
    "print(\"SVM Accuracy Score -> \", accuracy_score(predictions_svm, test_Y)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Accuracy Score ->  77.77777777777779\n"
     ]
    }
   ],
   "source": [
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='modified_huber', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None))\n",
    "               ])\n",
    "# other loss functions: log, hinge\n",
    "sgd.fit(train_X, train_Y)\n",
    "predictions_sgd = sgd.predict(test_X)\n",
    "\n",
    "print(\"SGD Accuracy Score -> \", accuracy_score(predictions_sgd, test_Y)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy Score ->  88.88888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "logreg.fit(train_X, train_Y)\n",
    "predictions_lr = logreg.predict(test_X)\n",
    "\n",
    "print(\"Logistic Regression Accuracy Score -> \", accuracy_score(predictions_lr, test_Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.6968489685754431)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = word_tokenize(text)\n",
    "    \n",
    "    final_words = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for word, tag in pos_tag(text):\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            final_word = lemmatizer.lemmatize(word, tag_map[tag[0]])\n",
    "            final_words.append(final_word)\n",
    "    return str(final_words)\n",
    "\n",
    "def predict_class(sentence):    \n",
    "    text = [preprocess(sentence)]\n",
    "    return svm.predict(text)[0], max(svm.predict_proba(text)[0])\n",
    "\n",
    "predict_class('lying')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
